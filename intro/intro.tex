

People play games. People write programs to play games. Strong programs need many techniques. I apply these techniques to Havannah and come up with some new techniques, some Havannah specific, and some general.

\section{Rules of Havannah}


\begin{figure}[tb]
\centering
\begin{HavannahBoard}[board size=6,coordinate style=classical]
\HStoneGroup[color=black,label=$\mathcal F$]{e10,f10,g10,g9,h9,h8,i8,j8,h7,h6,h5,i5,i4,k8}
\HStoneGroup[color=white,label=$\mathcal B$]{a1,a2,b3,c3,d4,e4,e3,e2,f2,f1}
\HStoneGroup[color=transparent,label=$\mathcal R$]{e7,e8,d8,c8,b7,b6,b5,c5,d6}
\end{HavannahBoard}
\caption{The three winning conditions as shown on a size 6 Havannah board}
\label{fig:rules}
\end{figure}

Havannah is a connection game invented in 1979 by Christian Freeling. It is a two player, zero-sum, perfect information game played on a hexagonal board. Each turn a player places a piece on the board in alternating play. The three winning conditions are shown in Figure \ref{fig:rules}:
\begin{itemize}
	\setlength{\itemsep}{0pt}
	\setlength{\parskip}{0pt}
	\setlength{\parsep}{0pt}
	\item A Fork is a group of stones that links 3 edges (corners are not part of either edge)
	\item A Bridge is a group of stones that links 2 corners
	\item A Ring is a group of stones that surround at least one cell (which can be empty or filled by either player)
\end{itemize}

Havannah is played on board sizes ranging from 4 to 10 cells per side. Better players prefer bigger boards due to the larger component of strategy compared to the small boards where tactics dominate. In 2002, Christian Freeling offered 1000 Euro for any program that beats him in just one in ten games on size 10 by 2012.

Havannah is considered hard to play for computers for several reasons including the lack of a heuristic evaluation function, few expert games, and a large state space complexity. It is often compared to Hex, which is also a connection game, but very few of the mathematical properties of  Hex apply in Havannah. 

\\- ties are possible
\\- both players can have forced wins, race to completion
\\- virtual connections can be broken
\\- multiple win conditions
\\- fork isn't a simple connection
\\- multiple ways for each win condition to occur (ie any 2 corners or 3 edges)
\\- rings can't be found as easily


\section{Playing and Solving Techniques}

Here are general game playing concepts:

\begin{description}
\item[Perfect Information] A game has the property of perfect information when both players know the full state of the game. There is no hidden information, such as cards in a hand, nor elements of randomness such as a dice.
\item[Zero Sum Games] A zero sum game means that one players gain is the other players loss. A draw is still possible, but no move can help both players, so there is no incentive to cooperate.
\item[State] A state is a full description of a board position. It includes the locations of all the pieces, and any other relevant information. In chess, the state would include whether each king can castle, or whether a pawn can capture en passant. In games where repeated moves are not allowed, the full game history may be included in the state. Occasionally a simplified version of the state is used when speed is more relevant than accuracy.
\item[Move] A move is a distinct action by one of the players. In games with multi-part moves, such as Amazons where each move consists of a movement plus shooting an arrow, the pair of actions would be considered a single move. There are usually multiple moves available from each state, and only one can be chosen per turn.
\item[Branching Factor] is the number of moves available to each player on average. This usually depends on board size and the stage of the game. This can be as low as 1 for forced moves, or very high, such as in the hundreds or thousands for Amazons or Arimaa.
\item[Game Tree] Games can be represented as a game tree. Each position in the game is a node, and each move is an edge in the graph connecting the position before the move to the position after the move. When there are multiple paths to a position, it can be represented as separate nodes, leading to a tree, or combined as a single node, leading to a directed acyclic graph (DAG). Some games have loops, where a position can be reached multiple times in a single game.
\item[Node Value] Each node has an associated outcome or expected outcome associated with it. Terminal positions are positions where one of the players has won or it is a draw, have an exact value such as win, loss or draw, or a score to show how much a player won by.
\item[Heuristic] A heuristic function takes a position and returns a heuristic value associated with the position. This value often representing a likelihood of winning from that position, but can also be just an abstract number that can be compared against other heuristic values to order nodes or moves.
\item[State Complexity] is the number of unique reachable states in the game.
\item[Minimax] In 2-player games, each player attempts to win at the expense of the other player. To do so, each player attempts to minimize the opponents gain while maximizing his own gain.
\item[Minimax Backup] Given a node N who's children all have known values, N's value is equal to the value of the most favourable child for the current player.
\item[Minimax Value] The value of a node given both players play perfectly according to Minimax.
\end{description}

Game playing programs all build a game tree, and then chose the most promising move. 

\subsection{Alpha-Beta}

Alpha-beta is an improvement over a simple implementation of minimax. It stops exploring or prunes parts of the tree that cannot have an effect on the minimax value of the root of the tree.


\subsection{Proof Number Search}



\subsection{Monte Carlo Tree Search}

Monte Carlo Tree Search is an algorithm for building and exploring a game tree. It consists of four phases:
\begin{description}
\item[Descent] This phase descends the game tree from the root to a leaf node in the game tree. At each node one of the available moves is selected according to some criteria based on previous performance or heuristic knowledge. When the Upper Confidence Bounds (UCB) formula is used, this is called UCT, but other formulas have been developed and are commonly used. RAVE is a modification of this formula.
\item[Expansion] If the leaf node has has experience from a previous simulation, its children are expanded, increasing the size of the tree.
\item[Rollout] A random game is played from the leaf node through the newly expanded children, to the end of the game. Heuristics can be used to make the moves less random and more representative of a real game. The strength of the overall algorithm is highly dependent on the average outcome of the random games being representative of the strength of the position.
\item[Back-propagation] The outcome of the random game in the rollout is back propagated to the moves chosen in the tree. The winning rate of the moves made by the player that won the rollout is increased while winning rate of the moves by the player that lost the rollout is decreased.
\end{description}

These four steps are repeated continually until time or memory runs out.





