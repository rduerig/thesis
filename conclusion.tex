% vim: set wrap

\section{Conclusions}

Several properties of Havannah were introduced in Section \ref{sec:properties}. Virtual connections and frames, while important, are yet to be exploited to their full potential. Dead cells may show up in generalized pattern recognition, but are not worth searching for on their own. Draws, while rare, can be detected early, and this is shown to be important in solving size 4. These properties together show some of the challenges and future potential of Havannah playing programs.

Monte Carlo Tree Search is shown to play Havannah very well. Many improvements are possible to increase the playing strength, including heuristic knowledge to modify the move selection in the descent phase, as well as modifications to the rollout policy.

The three winning conditions are shown to interact poorly with MCTS on big board sizes, and four fixes are proposed. The permanent stone ring rule proved to work very well at fixing these interactions, and significantly improves play on big boards against both other programs and against humans.

Several heuristics showed significant improvements in playing strength on their own, some as high as a 75\% winning rate or 200 elo. When combining all of the positive results, a winning rate of over 80\%, or about 300 elo is achieved on all board sizes greater than size 4.

This player, which includes proof backups, was then multi-threaded, given draw detection and better memory management. This improved player was then used to solve all 6 openings of the size 4 board. Proof trees for all 6 openings are presented in Section \ref{sec:size4proof}.

Castro, the implementation and test bed for all these tests is released open source and is available at \url{https://github.com/tewalds/castro}. ParamLog, the distributed testing framework that was used to run most of these tests is also open source and available at \url{https://github.com/tewalds/ParamLog}.




\section{Future Work}

There is a long way to go before Havannah programs are comparable strength to strong human players, even after all the improvements presented here. Thankfully there are also many potential improvements left to try and to discover. Many ideas that have been tried in other games, such as Go, could be tried here. One of the large successes in Go is to use patterns, both small and large, both as heuristic knowledge and to improve the rollout policy. The strength of these patterns can be learnt based on strong human games or even just strong games in self-play.

The large-scale parameter tuning that was used to generate all the results in Chapter \ref{playing} works, and is an effective way of understanding why a particular feature works. It is very inefficient, however, in terms of examining the state space of all the different features to find optimal parameters. A technique like minorization-maximization, which computes an elo rating for each feature, could be much more efficient. This would help show which features are strong and which can be inferred from the other features.

Section \ref{sec:vc} showed that virtual connections, and therefore frames, are breakable. Despite this, frames are the foundation of how humans play. The first program to successfully make solid deductions based on frames, without paying a huge speed penalty, is likely to have a large advantage over all others. Even just using frames as a guide for a solver could be a large performance boost.

Using a hash table instead of a tree to reduce transpositions could significantly improve performance with longer times to play and on the smaller board sizes where transpositions are frequently reached. It does, however, present significant engineering challenges in terms of garbage collection and threading, and does introduce a tiny probability of inaccuracy in the form of hash collisions.



%\begin{itemize}

%\item copy proofs

%\item opening book
%\item shared tree between games (ie database)

%\item proof number search player
%\item share a tree between mcts and pns
%\end{itemize}

%tune against lajkonik!

